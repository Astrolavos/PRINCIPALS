{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2de7dab-86a6-4eb4-ba01-bf24bfc15eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70834236-c1c6-4569-8697-c36b7e66e96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "627256ee-8c71-4536-be05-2a618fcf4d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run extract_features.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b358cef3-c3d6-424b-aba1-0f73609b47ef",
   "metadata": {},
   "source": [
    "## Input Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55da3d29-00f0-45f5-934a-501d3230b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbaiot_data = get_data_nbaiot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51c59df6-d07f-4533-be4d-ed1a706f7cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(data, pca_enabled=False, percentile=98, number_of_clusters=3, max_iter=sys.maxsize):\n",
    "    res = {}\n",
    "    num_samples = int(min([data[id].shape[0] for id in data.keys()]) / 2)\n",
    "    print(f\"using {num_samples} points for each device\") \n",
    "    for id_1 in data.keys():\n",
    "        if max_iter < 0:\n",
    "            break\n",
    "        max_iter -= 1\n",
    "        dev_id = id_1\n",
    "        train_data, test_data, _, labels = train_test_split(data[dev_id], np.full(len(data[dev_id]), dev_id), test_size=num_samples, random_state=42)\n",
    "        print(test_data.shape)\n",
    "        for id_2 in data.keys():\n",
    "            if id_1 != id_2:\n",
    "                _, tmp_data, _, tmp_labels = train_test_split(data[id_2], np.full(len(data[id_2]), id_2), test_size=num_samples, random_state=42)\n",
    "                test_data = np.concatenate((test_data, tmp_data), axis=0)\n",
    "                labels = np.concatenate((labels, tmp_labels), axis=0)\n",
    "        print(f\"Amount of test data per class {Counter(labels)}\")\n",
    "        print(\"Standardizing data\")\n",
    "        scaler = StandardScaler()\n",
    "        train_scaled = scaler.fit_transform(train_data)\n",
    "        test_scaled = scaler.transform(test_data)\n",
    "        \n",
    "        if pca_enabled:\n",
    "            print(\"Using PCA\")\n",
    "            pca_component_num = 100\n",
    "            pca = PCA(copy=True, iterated_power='auto', n_components=pca_component_num, random_state=None, whiten=False, svd_solver='auto', tol=0.0)\n",
    "            pca.fit(train_scaled)\n",
    "\n",
    "            train_scaled = pca.transform(train_scaled)\n",
    "            test_scaled = pca.transform(test_scaled)\n",
    "        else:\n",
    "            print(\"NOT using PCA\")\n",
    "            \n",
    "        #KMEANS\n",
    "        kmeans = KMeans(n_clusters=number_of_clusters, init='k-means++')\n",
    "        kmeans.fit(train_scaled)\n",
    "        \n",
    "        \n",
    "        min_distances = kmeans.transform(train_scaled).min(axis=1)\n",
    "        threshold = np.percentile(min_distances, percentile)\n",
    "        print(f\"KMeans threshold is {threshold}\")\n",
    "        \n",
    "        min_distances = kmeans.transform(test_scaled).min(axis=1)\n",
    "        res[id_1] = Counter(labels[min_distances < threshold])\n",
    "        print(res[id_1])\n",
    "    for key1 in res:\n",
    "        for key2 in res[key1]:\n",
    "            res[key1][key2] /= num_samples\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f54edc04-a9cb-407b-803d-de8d32bc7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "res = confusion_matrix(nbaiot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "575506b5-b914-47eb-beb4-28d4fa7366f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res = {}\n",
    "for id1 in res:\n",
    "    final_res[id1] = {}\n",
    "    for id2 in res:\n",
    "        final_res[id1][id2] =  res[id1][id2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6c75fb-e6ab-4e8a-9160-bc9296e98438",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(pd.DataFrame(final_res),annot=True)\n",
    "plt.xlabel(\"Train Device\")\n",
    "plt.ylabel(\"Test Device\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/data/thomas/Principals/FL/nbaiot.pdf\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67f71662-cbd2-46ee-8b3b-388f64d7af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "iot_lab_data = get_astrolavos_data(\"/data/thomas/Principals/testcases/FL4IOT/data/IOTLab/grouped_bigram_features_big\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23432b52-5c32-423e-8b59-9ce52775675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%capture\n",
    "res = confusion_matrix(iot_lab_data, max_iter=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f305ff-1812-47ff-94fc-7bf8924ee20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "_ = sns.heatmap(pd.DataFrame(res),annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
